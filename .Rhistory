learn_rate      = tune(),
loss_reduction  = tune()
) %>%
set_engine("xgboost")
wflw_spec_xgboost_tune <- workflow() %>%
add_model(model_spec_xgboost_tune) %>%
add_recipe(recipe_spec_ml)
# Tuning
set.seed(123)
tune_results_xgboost <- wflw_spec_xgboost_tune %>%
tune_grid(
resamples  = resamples_kfold,
param_info = extract_parameter_set_dials(wflw_spec_xgboost_tune) %>%
update(
learn_rate = learn_rate(range = c(0.001, 0.400), trans = NULL)
),
grid = 10,
control = control_grid(verbose = TRUE, allow_par = TRUE)
)
# ** Results
tune_results_xgboost %>% show_best("rmse", n = Inf)
# ** Finalize
set.seed(123)
wflw_fit_xgboost_tuned <- wflw_spec_xgboost_tune %>%
finalize_workflow(select_best(tune_results_xgboost, "rmse")) %>%
fit(training(splits))
library(doParallel)
parallel_stop()
detectCores()
doParallel::registerDoParallel(cores = 7)
model_spec_rf_tune <- rand_forest(
mode    = "regression",
mtry    = tune(),
trees   = tune(),
min_n   = tune()
) %>%
set_engine("ranger")
wflw_spec_rf_tune <- workflow() %>%
add_model(model_spec_rf_tune) %>%
add_recipe(recipe_spec_ml)
# ** Tuning
set.seed(123)
tune_results_rf <- wflw_spec_rf_tune %>%
tune_grid(
resamples = resamples_kfold,
grid      = 5,
control   = control_grid(verbose = TRUE, allow_par = TRUE)
)
# ** Results
best_rf_tuned <- tune_results_rf %>% show_best("rmse", n = Inf)
# ** Finalize
set.seed(123)
wflw_fit_rf_tuned <- wflw_spec_rf_tune %>%
finalize_workflow(select_best(tune_results_rf, "rmse")) %>%
fit(training(splits))
model_spec_knn_tune <- nearest_neighbor(
mode        = "regression",
neighbors   = tune(),
dist_power  = tune(),
weight_func = "optimal"
) %>%
set_engine("kknn")
wflw_spec_knn_tune <- workflow() %>%
add_model(model_spec_knn_tune) %>%
add_recipe(recipe_spec_ml)
# ** Tuning
set.seed(123)
tune_results_knn <- wflw_spec_knn_tune %>%
tune_grid(
resamples = resamples_kfold,
grid      = 5,
control   = control_grid(verbose = TRUE, allow_par = TRUE)
)
# ** Results
best_knn_tuned <- tune_results_knn %>% show_best("rmse", n = Inf)
# ** Finalize
set.seed(123)
wflw_fit_knn_tuned <- wflw_spec_knn_tune %>%
finalize_workflow(select_best(tune_results_knn, "rmse")) %>%
fit(training(splits))
submodels_2_tbl <- modeltime_table(
wflw_fit_xgboost_tuned,
wflw_fit_rf_tuned,
wflw_fit_knn_tuned
) %>%
update_model_description(1, "xgboost tuned") %>%
update_model_description(2, "rf tuned") %>%
update_model_description(3, "knn tuned") %>%
combine_modeltime_tables(submodels_1_tbl)
# calibrate
calibration_tbl <- submodels_2_tbl %>%
modeltime_calibrate(
new_data = testing(splits),
id = "listing_id")
# calibrate
calibration_tbl <- submodels_2_tbl %>%
modeltime_calibrate(
new_data = testing(splits),
id = "id")
# forecast on daily_prepared_tbl
forecast_test_tbl <- calibration_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = daily_prepared_tbl,
conf_by_id  = T,
keep_data   = T) %>%
mutate(across(
.cols = c(.value:.conf_hi, rate),
.fns  = expm1
))
calibration_tbl %>%
modeltime_accuracy(acc_by_id = FALSE) %>%
arrange(rmse)
forecast_test_tbl <- calibration_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = weekly_prepared_tbl,
conf_by_id  = T,
keep_data   = T) %>%
forecast_test_tbl
forecast_test_tbl <- calibration_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = weekly_prepared_tbl,
conf_by_id  = T,
keep_data   = T) %>%
forecast_test_tbl
# forecast on daily_prepared_tbl
forecast_test_tbl <- calibration_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = weekly_prepared_tbl,
conf_by_id  = T,
keep_data   = T) %>%
mutate(across(
.cols = c(.value:.conf_hi, weekly_sales),
.fns  = expm1
))
View(forecast_test_tbl)
# visualize
forecast_test_tbl %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 3,
.title = "All Test Forecasts")
# visualize
forecast_test_tbl %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 2,
.title = "All Test Forecasts")
# visualize
forecast_test_tbl %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 1,
.title = "All Test Forecasts")
# visualize
forecast_test_tbl %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 3,
.title = "All Test Forecasts")
# visualize
forecast_test_tbl %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = F,
.facet_ncol  = 3,
.title = "All Test Forecasts")
# * ACCURACY CHECK ----
submodels_1_tbl <- modeltime_table(
wflw_fit_xgb_1,
wflw_fit_xgb_2,
wflw_fit_rf,
wflw_fit_prophet,
wflw_fit_prophet_boost,
wflw_fit_thief,
wflw_fit_glmnet,
wflw_fit_mars,
wflw_fit_svm_rdl,
wflw_fit_knn,
wflw_fit_cubist,
wflw_fit_nnet,
wflw_fit_nnetar
) %>%
update_model_description(1, "xgb 1") %>%
update_model_description(2, "xgb 2") %>%
update_model_description(3, "rf") %>%
update_model_description(4, "prophet") %>%
update_model_description(5, "prophet boost") %>%
update_model_description(6, "thief") %>%
update_model_description(7, "glmnet") %>%
update_model_description(8, "mars") %>%
update_model_description(9, "svm rdl") %>%
update_model_description(10, "knn") %>%
update_model_description(11, "cubist") %>%
update_model_description(12, "nnet") %>%
update_model_description(13, "nnetar")
# calibrate on testing data -- LONG RUNNING SCRIPT!
submodels_calibrate <- submodels_1_tbl %>%
modeltime_calibrate(new_data = testing(splits), id = "id")
# GLOBAL accuracy
submodels_calibrate %>%
modeltime_accuracy(acc_by_id = FALSE) %>%
arrange(rmse)
# ACCURACY BY ID
submodels_calibrate %>%
modeltime_accuracy(acc_by_id = TRUE) %>%
table_modeltime_accuracy()
submodels_2_tbl <- modeltime_table(
wflw_fit_xgboost_tuned,
wflw_fit_rf_tuned,
wflw_fit_knn_tuned
) %>%
update_model_description(1, "xgboost tuned") %>%
update_model_description(2, "rf tuned") %>%
update_model_description(3, "knn tuned") %>%
combine_modeltime_tables(submodels_1_tbl)
# calibrate
calibration_tbl <- submodels_2_tbl %>%
modeltime_calibrate(
new_data = testing(splits),
id = "id")
calibration_tbl %>%
modeltime_accuracy(acc_by_id = FALSE) %>%
arrange(rmse)
# Accuracy
calibration_tbl %>%
modeltime_accuracy(acc_by_id = T) %>%
table_modeltime_accuracy()
# forecast on daily_prepared_tbl
forecast_test_tbl <- calibration_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = weekly_prepared_tbl,
conf_by_id  = T,
keep_data   = T) %>%
mutate(across(
.cols = c(.value:.conf_hi, weekly_sales),
.fns  = expm1
))
# visualize
forecast_test_tbl %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 3,
.title = "All Test Forecasts")
tempdir()
dir.create(tempdir())
# 1.0 LIBRARIES ----
# Machine Learning
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(modeltime.resample)
# Time Series
library(timetk)
# Core
library(tidyverse)
library(trelliscopejs)
library(janitor)
#EDA
library(DataExplorer)
# Machine Learning
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(modeltime.resample)
library(prophet)
library(rules)
library(trelliscopejs)
library(ranger)
library(randomForest)
library(recipes)
library(kknn)
library(kernlab)
library(thief)
library(Cubist)
options(scipen = 9999)
# visualize
forecast_test_tbl %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 3,
.title = "All Test Forecasts")
#select the best with RMSE
calibration_best_tbl<-calibaration_tbl %>%
modeltime_accuracy(acc_by_id = TRUE) %>%
group_by(id) %>%
slice_min(rmse) %>%
slice_min(.model_id) %>%
ungroup()
#select the best with RMSE
calibration_best_tbl<- calibration_tbl %>%
modeltime_accuracy(acc_by_id = TRUE) %>%
group_by(id) %>%
slice_min(rmse) %>%
slice_min(.model_id) %>%
ungroup()
#Check Accuracy
calibration_best_tbl %>%
table_modeltime_accuracy()
submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id)
modeltime_baseline_tbl <- submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id) %>%
select(.model_id, .model, .model_desc.x) %>%
rename(.model_desc = model_desc.x)
modeltime_baseline_tbl <- submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id) %>%
select(.model_id, .model, .model_desc.x) %>%
rename(.model_desc = model_desc.x)
modeltime_baseline_tbl <- submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id) %>%
select(.model_id, .model, .model_desc.x) %>%
rename(.model_desc = model_desc.x)
modeltime_baseline_tbl <- submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id) %>%
select(.model_id, .model, .model_desc.x) %>%
rename(.model_desc = model_desc.x)
modeltime_baseline_tbl <- submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id)
#calibrate again with reduced baseline list
calibration_baseline_tbl <- modeltime_baseline_tbl %>%
modeltime_calibrate(testing(splits), id = "id")
modeltime_baseline_tbl <- submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id) %>%
select(.model_id, .model, .model_desc.x) %>%
rename(.model_desc = model_desc.x)
modeltime_baseline_tbl <- submodels_2_tbl %>%
inner_join(calibration_best_tbl, by = ".model_id") %>%
arrange(id) %>%
select(.model_id, .model, .model_desc.x) %>%
rename(.model_desc = .model_desc.x)
#calibrate again with reduced baseline list
calibration_baseline_tbl <- modeltime_baseline_tbl %>%
modeltime_calibrate(testing(splits), id = "id")
#select the best with RMSE
calibration_best_tbl<- calibration_tbl %>%
modeltime_accuracy(acc_by_id = TRUE) %>%
group_by(id) %>%
slice_min(rmse) %>%
slice_min(.model_id) %>%
ungroup()
#Check Accuracy
calibration_best_tbl %>%
table_modeltime_accuracy()
data_forecasted <- calibration_baseline_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = weekly_prepared_tbl,
conf_by_id  = TRUE,
keep_data   = TRUE
)
#### FUNCTION: keep up to specific column name #####
keep_up_to <- function(df, colname){
col_i <- which(colnames(data_forecasted) == colname)
df[(1:col_i)]
}
# example...
data_forecasted %>%
keep_up_to("weekend")
#### FUNCTION: keep up to specific column name #####
keep_up_to <- function(df, colname){
col_i <- which(colnames(data_forecasted) == colname)
df[(1:col_i)]
}
data_forecasted <- calibration_baseline_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = weekly_prepared_tbl,
conf_by_id  = TRUE,
keep_data   = TRUE
)
# example...
data_forecasted %>%
keep_up_to("weekend")
View(weekly_prepared_tbl)
# create test forecast for best models
final_baseline_models <- data_forecasted %>%
filter(.key == "actual") %>%
bind_rows(
data_forecasted %>%
filter(.key == "prediction") %>%
inner_join(calibration_best_models, by = c("id", ".model_id")) %>%
keep_up_to(rev(names(data_forecasted))[1]) %>%
rename(.model_desc = .model_desc.x)
)
# create test forecast for best models
final_baseline_models <- data_forecasted %>%
filter(.key == "actual") %>%
bind_rows(
data_forecasted %>%
filter(.key == "prediction") %>%
inner_join(calibration_best_tbl, by = c("id", ".model_id")) %>%
keep_up_to(rev(names(data_forecasted))[1]) %>%
rename(.model_desc = .model_desc.x)
)
# visualize
final_baseline_models %>%
group_by(listing_id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 3,
.title = "Best Test Forecasts")
# visualize
final_baseline_models %>%
group_by(id) %>%
plot_modeltime_forecast(
.conf_interval_show = F,
.trelliscope = T,
.facet_ncol  = 3,
.title = "Best Test Forecasts")
# 1.0 LIBRARIES ----
# Machine Learning
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(modeltime.resample)
# Time Series
library(timetk)
# Core
library(tidyverse)
library(trelliscopejs)
library(janitor)
#EDA
library(DataExplorer)
# Machine Learning
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(modeltime.resample)
library(prophet)
library(rules)
library(trelliscopejs)
library(ranger)
library(randomForest)
library(recipes)
library(kknn)
library(kernlab)
library(thief)
library(Cubist)
options(scipen = 9999)
data_forecasted <- calibration_baseline_tbl %>%
modeltime_forecast(
new_data    = testing(splits),
actual_data = weekly_prepared_tbl,
conf_by_id  = TRUE,
keep_data   = TRUE
)
#### FUNCTION: keep up to specific column name #####
keep_up_to <- function(df, colname){
col_i <- which(colnames(data_forecasted) == colname)
df[(1:col_i)]
}
# example...
data_forecasted %>%
keep_up_to("2012-10-26")
tempdir()
dir.create(tempdir())
# 1.0 LIBRARIES ----
# Machine Learning
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(modeltime.resample)
# Time Series
library(timetk)
# Core
library(tidyverse)
library(trelliscopejs)
library(janitor)
#EDA
library(DataExplorer)
# Machine Learning
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(modeltime.resample)
library(prophet)
library(rules)
library(trelliscopejs)
library(ranger)
library(randomForest)
library(recipes)
library(kknn)
library(kernlab)
library(thief)
library(Cubist)
options(scipen = 9999)
